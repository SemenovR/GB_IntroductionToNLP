{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Part-of-Speech разметка, NER , извлечение отношений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема “Улучшение качества  POS-taggera”\n",
    "\n",
    "На вебинаре был рассмотрен пример тегирования с использованием корпуса на Русском языке, вам необходимо улучшить модель что бы качество классификации было выше чем с лог регрессией \n",
    "\n",
    "### Тема “Создание признакового пространства”\n",
    "\n",
    "Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'.\n",
    "##### Задание 1.\n",
    "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)\n",
    "\n",
    "\n",
    "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
    "\n",
    "\n",
    "Повторим шаги из заданий 1 и 2, используя библиотеку nltk.\n",
    "##### Задание 2.\n",
    "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
    "\n",
    "\n",
    "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
    "\n",
    "##### Задание 3.\n",
    "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема “Улучшение качества  POS-taggera”\n",
    "\n",
    "На вебинаре был рассмотрен пример тегирования с использованием корпуса на Русском языке, вам необходимо улучшить модель что бы качество классификации было выше чем с лог регрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyconll\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\n",
    "full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "test_enc_labels = le.transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvectorizer = HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=100)\n",
    "X_train = hvectorizer.fit_transform(train_tok)\n",
    "X_test = hvectorizer.transform(test_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вариант обучения на логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rseme\\.conda\\envs\\tf2-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7213460047854953"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0, max_iter=100)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "pred = lr.predict(X_test)\n",
    "accuracy_score(test_enc_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вариант обучения на RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942818387085903"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lgb = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    verbose=False,\n",
    "    n_jobs=8,\n",
    "    random_state=27\n",
    ")\n",
    "lgb.fit(X_train, train_enc_labels)\n",
    "pred = lgb.predict(X_test)\n",
    "accuracy_score(test_enc_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема “Создание признакового пространства”\n",
    "\n",
    "Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'.\n",
    "##### Задание 1.\n",
    "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_md\n",
    "from spacy import displacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>prep_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>when father is dysfunctional and is so selfish he drags his kids into his dysfunction run</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so, selfish, he, drags, his, kids, into, his, dysfunction, run]</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, dysfunction, run]</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunct, run]</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dysfunction, run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thanks for lyft credit cannot use cause they do not offer wheelchair vans in pdx disapointed getthanked</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cause, they, do, not, offer, wheelchair, vans, in, pdx, disapointed, getthanked]</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, wheelchair, vans, pdx, disapointed, getthanked]</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelchair, van, pdx, disapoint, getthank]</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheelchair, vans, pdx, disapointed, getthanked]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                                                                                                       tweet                                                                                               prep_tweet                                                                                                                  tweet_token                                                                       tweet_token_filtered                                                                       tweet_stemmed                                                                          tweet_lemmatized\n",
       "0   1    0.0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                when father is dysfunctional and is so selfish he drags his kids into his dysfunction run                   [when, father, is, dysfunctional, and, is, so, selfish, he, drags, his, kids, into, his, dysfunction, run]                            [father, dysfunctional, selfish, drags, kids, dysfunction, run]                               [father, dysfunct, selfish, drag, kid, dysfunct, run]                             [father, dysfunctional, selfish, drag, kid, dysfunction, run]\n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  thanks for lyft credit cannot use cause they do not offer wheelchair vans in pdx disapointed getthanked  [thanks, for, lyft, credit, can, not, use, cause, they, do, not, offer, wheelchair, vans, in, pdx, disapointed, getthanked]  [thanks, lyft, credit, use, cause, offer, wheelchair, vans, pdx, disapointed, getthanked]  [thank, lyft, credit, use, caus, offer, wheelchair, van, pdx, disapoint, getthank]  [thank, lyft, credit, use, cause, offer, wheelchair, vans, pdx, disapointed, getthanked]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"lesson_01.pkl\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()\n",
    "ner = data['prep_tweet'].apply(lambda x: [[doc.ent_type_, doc.text ] for doc in nlp(x) if doc.ent_type_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_top20 = []\n",
    "c_ner = []\n",
    "c_person = []\n",
    "c_org = []\n",
    "\n",
    "for row in ner:\n",
    "    for el in row:\n",
    "        c_top20.append(f'{el[1]} ({el[0]})')\n",
    "        c_ner.append(el[0])\n",
    "        if el[0] == 'PERSON':\n",
    "            c_person.append(f'{el[1]} ({el[0]})')\n",
    "        if el[0] == 'ORG':\n",
    "            c_org.append(f'{el[1]} ({el[0]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ТОП-20 популярных NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('today (DATE)', 1438),\n",
       " ('day (DATE)', 1276),\n",
       " ('friday (DATE)', 752),\n",
       " ('the (DATE)', 615),\n",
       " ('tomorrow (DATE)', 612),\n",
       " ('morning (TIME)', 611),\n",
       " ('weekend (DATE)', 561),\n",
       " ('summer (DATE)', 555),\n",
       " ('one (CARDINAL)', 548),\n",
       " ('sunday (DATE)', 546),\n",
       " ('week (DATE)', 546),\n",
       " ('days (DATE)', 539),\n",
       " ('first (ORDINAL)', 512),\n",
       " ('yoyour (GPE)', 499),\n",
       " ('this (DATE)', 498),\n",
       " ('orlando (GPE)', 497),\n",
       " ('tonight (TIME)', 431),\n",
       " ('year (DATE)', 409),\n",
       " ('night (TIME)', 403),\n",
       " ('bihday (DATE)', 355)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(c_top20).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PERSON', 22462)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(c_ner).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bihday (PERSON)', 334),\n",
       " ('bing (PERSON)', 214),\n",
       " ('bong (PERSON)', 214),\n",
       " ('obama (PERSON)', 131),\n",
       " ('hillary (PERSON)', 88),\n",
       " ('th (PERSON)', 88),\n",
       " ('suppo (PERSON)', 83),\n",
       " ('sta (PERSON)', 81),\n",
       " ('bull (PERSON)', 79),\n",
       " ('trump (PERSON)', 71),\n",
       " ('donald (PERSON)', 64),\n",
       " ('hu (PERSON)', 62),\n",
       " ('christina (PERSON)', 57),\n",
       " ('am (PERSON)', 56),\n",
       " ('usd (PERSON)', 45),\n",
       " ('sun (PERSON)', 44),\n",
       " ('bjp (PERSON)', 44),\n",
       " ('john (PERSON)', 42),\n",
       " ('grimmie (PERSON)', 41),\n",
       " ('cox (PERSON)', 41)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(c_person).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buffalo (ORG)', 189),\n",
       " ('allahsoil (ORG)', 110),\n",
       " ('simulation (ORG)', 106),\n",
       " ('sjw (ORG)', 102),\n",
       " ('the (ORG)', 98),\n",
       " ('orlando (ORG)', 88),\n",
       " ('trump (ORG)', 78),\n",
       " ('gop (ORG)', 78),\n",
       " ('bihday (ORG)', 76),\n",
       " ('polar (ORG)', 68),\n",
       " ('bull (ORG)', 65),\n",
       " ('islam (ORG)', 64),\n",
       " ('nba (ORG)', 62),\n",
       " ('day (ORG)', 58),\n",
       " ('sun (ORG)', 54),\n",
       " ('hill (ORG)', 54),\n",
       " ('social (ORG)', 53),\n",
       " ('news (ORG)', 51),\n",
       " ('ht (ORG)', 50),\n",
       " ('new (ORG)', 49)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(c_org).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим шаги из заданий 1 и 2, используя библиотеку nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 2.\n",
    "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 3.\n",
    "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
